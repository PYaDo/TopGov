# Description: Configuration file for the project


[preprocessing]
# The tokenizer is used to tokenize the sentences within the Sent.py class.
# The tokenizer can be any of the transformer models from spaCy.
# An overview of the models can be found here: https://spacy.io/models/en
tokenizer = en_core_web_trf

[library]
storage = /Users/paul/Zotero/storage/

[data]
path = /Users/paul/Documents/FOM/MasterArbeit/Thesis/dev/data/